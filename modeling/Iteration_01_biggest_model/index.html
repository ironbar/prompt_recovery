
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://ironbar.github.io/prompt_recovery/modeling/Iteration_01_biggest_model/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.15">
    
    
      
        <title>Iteration 1. Biggest model - prompt_recovery</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.c382b1dc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cc9b2e1e.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="blue">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#iteration-1-biggest-model" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="prompt_recovery" class="md-header__button md-logo" aria-label="prompt_recovery" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            prompt_recovery
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Iteration 1. Biggest model
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ironbar/prompt_recovery" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../01_Business_Understanding/" class="md-tabs__link">
      Business Understanding
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../02_Data_Understanding/" class="md-tabs__link">
      Data Understanding
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../" class="md-tabs__link md-tabs__link--active">
        Modeling
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../05_Solution_Summary/" class="md-tabs__link">
      Solution Summary
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../utils/00_Challenge_Workflow/" class="md-tabs__link">
        Utils
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="prompt_recovery" class="md-nav__button md-logo" aria-label="prompt_recovery" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    prompt_recovery
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ironbar/prompt_recovery" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../01_Business_Understanding/" class="md-nav__link">
        Business Understanding
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../02_Data_Understanding/" class="md-nav__link">
        Data Understanding
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">Modeling</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Modeling" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Modeling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Iteration 1. Biggest model
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Iteration 1. Biggest model
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#goal" class="md-nav__link">
    Goal
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    Motivation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#development" class="md-nav__link">
    Development
  </a>
  
    <nav class="md-nav" aria-label="Development">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#candidates-study" class="md-nav__link">
    Candidates study
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-steps-with-mixtral" class="md-nav__link">
    First steps with Mixtral
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prompt-engineering-with-gemma-2b" class="md-nav__link">
    Prompt engineering with Gemma 2b
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mixtral-can-be-used-for-inference" class="md-nav__link">
    Mixtral can be used for inference
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-memory" class="md-nav__link">
    GPU Memory
  </a>
  
    <nav class="md-nav" aria-label="GPU Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#input-tokens" class="md-nav__link">
    Input tokens
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-tokens" class="md-nav__link">
    Output tokens
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    Batch size
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum-submission-input-tokens" class="md-nav__link">
    Maximum submission input tokens
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#which-llms-are-fast-enough-to-be-used-for-inference" class="md-nav__link">
    Which LLMs are fast enough to be used for inference?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    Next steps
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#todo" class="md-nav__link">
    TODO
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_02_prompt_engineering/" class="md-nav__link">
        Iteration 2. Prompt engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_03_study_leaked_data/" class="md-nav__link">
        Iteration 3. Study Leaked data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_04_create_new_data/" class="md-nav__link">
        Iteration 4. Create new data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_05_fine-tune_mixtral/" class="md-nav__link">
        Iteration 5. Mixtral fine-tuning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_06_few_shot_prompt_engineering/" class="md-nav__link">
        Iteration 6. Few shot prompt engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_07_pause_and_analysis/" class="md-nav__link">
        Iteration 7. Pause and analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_08_create_high_quality_hard_dataset/" class="md-nav__link">
        Iteration 8. Create a high quality hard dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_09_mean_prompt_optimization/" class="md-nav__link">
        Iteration 9. Mean prompt optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_10_fine-tune_on_high_quality_data/" class="md-nav__link">
        Iteration 10. Fine-tune on high quality data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_11_llama_2/" class="md-nav__link">
        Iteration 11. Llama 2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_12_other_models/" class="md-nav__link">
        Iteration 12. Fine-tuning Phi-2 and Gemma
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_13_datacentric_mistral/" class="md-nav__link">
        Iteration 13. Data centric approach around Mistral 7B
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_14_more_high_quality_data/" class="md-nav__link">
        Iteration 14. More high quality data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_15_prompt_tuning/" class="md-nav__link">
        Iteration 15. Prompt tuning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_16_similar_prompts/" class="md-nav__link">
        Iteration 16. Similar prompts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_17_scale_the_data/" class="md-nav__link">
        Iteration 17. Scale the data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_18_generate_data_with_gemma/" class="md-nav__link">
        Iteration 18. Generate data with Gemma
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_19_plan_last_submission/" class="md-nav__link">
        Iteration 19. Plan the last submissions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Iteration_n/" class="md-nav__link">
        Iteration n. Iteration_title
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../05_Solution_Summary/" class="md-nav__link">
        Solution Summary
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" data-md-state="indeterminate" type="checkbox" id="__nav_5" checked>
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5">
          Utils
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Utils" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Utils
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/00_Challenge_Workflow/" class="md-nav__link">
        Challenge workflow
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/markdown_cheatsheet/" class="md-nav__link">
        Markdown cheatsheet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/methodology/" class="md-nav__link">
        Methodology
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#goal" class="md-nav__link">
    Goal
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    Motivation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#development" class="md-nav__link">
    Development
  </a>
  
    <nav class="md-nav" aria-label="Development">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#candidates-study" class="md-nav__link">
    Candidates study
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-steps-with-mixtral" class="md-nav__link">
    First steps with Mixtral
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prompt-engineering-with-gemma-2b" class="md-nav__link">
    Prompt engineering with Gemma 2b
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mixtral-can-be-used-for-inference" class="md-nav__link">
    Mixtral can be used for inference
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-memory" class="md-nav__link">
    GPU Memory
  </a>
  
    <nav class="md-nav" aria-label="GPU Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#input-tokens" class="md-nav__link">
    Input tokens
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#output-tokens" class="md-nav__link">
    Output tokens
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    Batch size
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maximum-submission-input-tokens" class="md-nav__link">
    Maximum submission input tokens
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#which-llms-are-fast-enough-to-be-used-for-inference" class="md-nav__link">
    Which LLMs are fast enough to be used for inference?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-steps" class="md-nav__link">
    Next steps
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#todo" class="md-nav__link">
    TODO
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/ironbar/prompt_recovery/edit/master/docs/modeling/Iteration_01_biggest_model.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="iteration-1-biggest-model">Iteration 1. Biggest model</h1>
<p><em>18-03-2024</em></p>
<!---
The work is done using short iterations. Each iteration needs to have a very
clear goal. This allows to gain greater knowledge of the problem on each iteration.
--->

<h2 id="goal">Goal</h2>
<p>What is the biggest model that can be used to make a submission?</p>
<h2 id="motivation">Motivation</h2>
<p>Scaling laws say that bigger models give better results. To be competitive we have to use the
biggest model available for the challenge.</p>
<h2 id="development">Development</h2>
<h3 id="candidates-study">Candidates study</h3>
<p>The most popular open-source models are: Mistral, Llama, Phi and Gemma.</p>
<p>Since we want to use the biggest model possible that excludes Phi. Phi-2 model has just
2.7B parameters and the biggest Gemma model is 7B parameters.</p>
<p>Mistral releases claim that the Mistral 7B model is better than Llama 2 13B model (and of course better than Llama 2 7B). If we trust those claims it won't have sense to use Llama 2 models.</p>
<p><img alt="mistral_vs_llama" src="../res/mistral_vs_llama.png" /></p>
<p>Mixtral is the best model but it has 56B parameters, that will fit very tightly on 32GB of VRAM memory.
I have to test if I can make reliable predictions using Mixtral and wether I can fine-tune it.</p>
<p><img alt="mixtral_table" src="../res/mixtral_table.png" /></p>
<p>Google claims that Gemma is better than Mistral and Llama 2. The differences between Mistral 7B and Gemma 7B
seem to be context dependent. In some contexts like math and code Gemma is better, on reasoning and real life
scenarios Mistral seems to be better.</p>
<p><img alt="mixtral_is_the_best" src="../res/mixtral_is_the_best.png" /></p>
<p>If possible I should use Mixtral because it's the most powerful model available. If I'm unable to use
Mixtral then I should go with Mistral 7B or Gemma 7B.</p>
<p>Links:</p>
<ul>
<li><a href="https://mistral.ai/news/announcing-mistral-7b/">https://mistral.ai/news/announcing-mistral-7b/</a></li>
<li><a href="https://mistral.ai/news/mixtral-of-experts/">https://mistral.ai/news/mixtral-of-experts/</a></li>
<li><a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a></li>
<li><a href="https://www.ankursnewsletter.com/p/comparative-analysis-gemma-7b-vs">https://www.ankursnewsletter.com/p/comparative-analysis-gemma-7b-vs</a></li>
</ul>
<h3 id="first-steps-with-mixtral">First steps with Mixtral</h3>
<pre><code class="language-bash">conda create -n prometeo pytest rope pylint tqdm numpy pandas scikit-learn ipython ipykernel coverage ipywidgets matplotlib python=3.10 -y
conda activate prometeo
pip install autotransformers
</code></pre>
<p>Downloading the model from <a href="https://www.kaggle.com/models/mistral-ai/mixtral/frameworks/PyTorch/variations/8x7b-instruct-v0.1-hf/versions/1">Kaggle</a> took around 2 hours, it is a 151 GB <code>.tar.gz</code> file. However inside it has two
different formats, so the model ends up weighting around 93 GB, it seems that it is saved in <code>float16</code> format.</p>
<p>One trick was to copy the model to the SSD, I was able to read it in less than 1 minute, compared to 12 minutes in Kaggle and 24 minutes when reading from HDD.</p>
<p>Just by creating the environment with the instructions above, and downloading the model from Kaggle
I was able to run without trouble the model on my PC at a speed of 10 tokens/s.</p>
<h3 id="prompt-engineering-with-gemma-2b">Prompt engineering with Gemma 2b</h3>
<p>I have been playing with <code>Gemma 2b-it</code> because it is fast enough to be able to make predictions with it.</p>
<p>The problem is that <strong>the model is pretty dumb</strong>. Very frequently ignores the given instructions, so doing prompt engineering with the model is challenging.</p>
<p>One option could be to divide the task in two:</p>
<ol>
<li>Create a list with the differences between the two texts</li>
<li>Given the list of the differences summarize the differences into a prompt</li>
</ol>
<p>This is probably the chain of thought that a person will likely do to solve the problem.</p>
<h2 id="results">Results</h2>
<h3 id="mixtral-can-be-used-for-inference">Mixtral can be used for inference</h3>
<p>I have made a few <a href="https://www.kaggle.com/code/ironbar/prompt-engineering-with-mixtral">submissions</a> with tiny changes in input formatting and generation parameters that scored 0.51 and 0.52.
It's a pity that an LLM scores below a simple sentence like <code>Improve this text</code>, but the good thing is that
now I know that it is possible to use Mixtral for inference.</p>
<p>Thus Mixtral should be my preferred workhorse for this challenge. Unless I'm unable to finetune it I should
use Mixtral until the end of the challenge.</p>
<h3 id="gpu-memory">GPU Memory</h3>
<h4 id="input-tokens">Input tokens</h4>
<p><img alt="input tokens" src="../res/2024-03-21-11-10-24.png" /></p>
<p>Memory and inference time grow linearly with the input tokens.</p>
<h4 id="output-tokens">Output tokens</h4>
<p><img alt="output tokens" src="../res/2024-03-21-11-09-49.png" /></p>
<p>In the scale of the tokens that we are going generate, output memory is constant and inference time scales linearly.</p>
<h4 id="batch-size">Batch size</h4>
<p><img alt="" src="../res/2024-03-21-11-16-27.png" /></p>
<p>The memory grows linearly with the batch size, as expected. Unless we use a very small input size
on inference batching the inference won't be beneficial.</p>
<h3 id="maximum-submission-input-tokens">Maximum submission input tokens</h3>
<p>When loading the model there is a <code>device_map</code> parameter that it is set to <code>auto</code> in the code samples. This
results on an unbalanced memory usage between the GPUs as shown on the table below.</p>
<table>
<thead>
<tr>
<th>device_map</th>
<th>GPU 0 memory (GB)</th>
<th>GPU 1 memory (GB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>auto</td>
<td>10.3</td>
<td>13.2</td>
</tr>
<tr>
<td>create_shared_device_map(16)</td>
<td>11.8</td>
<td>11.8</td>
</tr>
<tr>
<td>create_intertwined_device_map()</td>
<td>11.8</td>
<td>11.8</td>
</tr>
</tbody>
</table>
<p>It seems I can do inference reliably with up to <strong>7200 input tokens</strong>. I needed to carefully balanced the layers of the model between the 2 gpus. With previous <code>auto</code> configuration only 3500 input tokens were allowed. Since I have been able to make a submission with the previous configuration that implies that none of the samples of the hidden test set had a higher input size of 3500 tokens.</p>
<p>It is not clear if <code>create_shared_device_map</code> is faster than <code>create_intertwined_device_map</code>. The first one splits the model in two halfs so the GPU 0 does the first stage of the model and GPU 1 the second stage. The intertwined
strategy assigns the layers alternatively to each GPU, thus it needs more communication between GPUs but it is likely
that heat dissipation would be better.</p>
<p>Mixtral has a maximum context window of 32k tokens, so we are very far from there.</p>
<h3 id="which-llms-are-fast-enough-to-be-used-for-inference">Which LLMs are fast enough to be used for inference?</h3>
<p>On a first step I tried different models, the table below shows the speed in tokens per second.</p>
<table>
<thead>
<tr>
<th>LLM</th>
<th>LMstudio Ubuntu</th>
<th>LMstudio Windows</th>
<th>Victor Windows</th>
<th>P4 gpu GGUF</th>
<th>4 bits 2xP4</th>
<th>4 bits 1xP4</th>
</tr>
</thead>
<tbody>
<tr>
<td>phi 2 3B q8</td>
<td>131</td>
<td>60</td>
<td></td>
<td>50</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Gemma 3B it</td>
<td>-</td>
<td>31</td>
<td></td>
<td>38</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Llama 2 7B q8</td>
<td>76</td>
<td>37</td>
<td></td>
<td>25</td>
<td>7.9</td>
<td>10.4</td>
</tr>
<tr>
<td>mistral 7B q8</td>
<td>75.5</td>
<td>40</td>
<td>60</td>
<td>23</td>
<td>10</td>
<td>11.3</td>
</tr>
<tr>
<td>Gemma 7B it q8</td>
<td>-</td>
<td>17</td>
<td>30</td>
<td>15</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Llama 2 13B</td>
<td></td>
<td></td>
<td></td>
<td>15</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mixtral</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>4.1</td>
</tr>
</tbody>
</table>
<p>Mixtral 8x7B is about twice as slow as Mistral 7B despite having 8 times more parameters. That is the
magic of sparse mixture of experts.</p>
<h2 id="conclusion">Conclusion</h2>
<p>It is possible to make submissions using Mixtral. It is the biggest and most capable model that can
be used for this challenge.</p>
<p>I could use an input size up to 7200 tokens, which is around 400 lines or 4700 words. That seems a lot of room to play with prompt engineering a few shot prompting.</p>
<h2 id="next-steps">Next steps</h2>
<h2 id="todo">TODO</h2>
<ul class="task-list">
<li class="task-list-item"><input type="checkbox" disabled checked/> Which LLMs are fast enough can be used for inference?</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> LLama 2</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Mistral 7B</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Phi-2</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Gemma</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Which speed can I get on my computer using lmstudio?</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Mixtral</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Can I make reliable inference with it?</li>
<li class="task-list-item"><input type="checkbox" disabled/> Can I fine-tune it?</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> https://www.kaggle.com/code/ashishkumarak/mixtral-moe-8x7b-instruct-inference-t4-2-gpu</li>
<li class="task-list-item"><input type="checkbox" disabled/> <a href="https://colab.research.google.com/drive/1VDa0lIfqiwm16hBlIlEaabGVTNB3dN1A?usp=sharing">Fine-tune Mixtral-8x7B on Your Computer (QLoRA)</a></li>
<li class="task-list-item"><input type="checkbox" disabled checked/> https://www.kaggle.com/models/mistral-ai/mixtral/frameworks/PyTorch/variations/8x7b-instruct-v0.1-hf/versions/1</li>
<li class="task-list-item"><input type="checkbox" disabled/> Which dataset was used to fine-tune Guanaco? On Qlora paper it is said that it was fine-tuned in less than one day</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> How can I make a submission with a HuggingFace model?</li>
<li class="task-list-item"><input type="checkbox" disabled/> How much could I improve the evaluation speed if using a more powerful GPU?</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> Which LLMs I can finetune and use for inference?</li>
<li class="task-list-item"><input type="checkbox" disabled checked/> <a href="https://www.youtube.com/watch?v=WYcJb8gYBZU">Fine-tuning de grandes modelos de lenguaje con Manuel Romero | Hackathon Somos NLP 2023</a> Está un poco anticuada porque es de hace un año pero la teoría está muy bien explicada.</li>
<li class="task-list-item"><input type="checkbox" disabled/> https://github.com/somosnlp/recursos/blob/main/hackathon_2024/entrenamiento_llm_instrucciones.ipynb</li>
</ul>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      2024-03-21
    
  </small>
</div>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../" class="md-footer__link md-footer__link--prev" aria-label="Previous: Modeling" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Modeling
            </div>
          </div>
        </a>
      
      
        
        <a href="../Iteration_02_prompt_engineering/" class="md-footer__link md-footer__link--next" aria-label="Next: Iteration 2. Prompt engineering" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Iteration 2. Prompt engineering
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://www.linkedin.com/in/guillermobarbadillo/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://twitter.com/guille_bar" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.youtube.com/channel/UCOHmUwHnd2hmUpiDzaQ1Isg" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.kaggle.com/ironbar" target="_blank" rel="noopener" title="www.kaggle.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M304.2 501.5 158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top"], "search": "../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.a6c66575.min.js"></script>
      
        <script src="../../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>