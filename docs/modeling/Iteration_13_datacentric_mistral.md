# Iteration 13. Data centric approach around Mistral 7B

_11-04-2024_

## Goal

What is the highest LB score I can get with Mistral 7B?

## Motivation

Training with Mistral is much faster than training with Mixtral. And the leaderboard results are the same.

On this iteration I'm going to change the training data and try to get the best possible LB score.

This is a continuation of iterations 8 and 10, but focusing on Mistral and the data.

## Development

## Results

## Conclusion

## Next steps

## TODO

- [ ] Is there any useful public dataset that I can use directly? Measure text length and prompt diversity.
- [ ] Collect useful prompts from other datasets
- [ ] Generate samples with multi-instruction prompts (similar to leaked data)
- [ ] Gain more control over wandb for easier inspection
