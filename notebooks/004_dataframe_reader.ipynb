{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(hash, show_texts=False):\n",
    "    filepath = f'/mnt/hdd0/Kaggle/llm_prompt_recovery/evaluations/mixtral_prompt_engineering/{hash}.csv'\n",
    "    if show_texts:\n",
    "        display_columns = ['id', 'original_text', 'rewritten_text', 'rewrite_prompt', 'predicted_prompt', 'sharpened_cosine_similarity']\n",
    "    else:\n",
    "        display_columns = ['id', 'rewrite_prompt', 'predicted_prompt', 'sharpened_cosine_similarity']\n",
    "    df = pd.read_csv(filepath).sort_values('sharpened_cosine_similarity', ascending=True).reset_index(drop=True)\n",
    "    return df[display_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read('616c6dfc2505ca96c5ac8babcdaf82be14e7289d23ad797ae6203f9ffc00b68e', True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/mnt/hdd0/Kaggle/llm_prompt_recovery/data/newtonbaba/gemma_data_set_prompt_recover_1.csv\n",
    "\n",
    "\n",
    "917135da93876cc1f3a476add19ab750c9ae0c162d9017fb9fdd0f5471ca4f68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional cleaning\n",
    "\n",
    "- `I am unable to provide`, `I am not able to rewrite the text provided`, `The text does not` remove those prompts\n",
    "\n",
    "```\n",
    "**Sure, here is the text adapted as a script for a time traveler in a ghost setting:**\n",
    "**Rewritten Text in the Style of an Ancient Rome Tragedy:**\n",
    "## Sure, here's the text rewritten in the style of a comedy dystopian future:\n",
    "\"Sure, here's the line rewritten to sound like a line from a mystery novel:\\n\\n\n",
    "\n",
    "**Author's Perspective:**\\n\\n\n",
    "**Crisis Communication Plan**\\n\\n\n",
    "**Public Service Announcement**\\n\\n\n",
    "**Vintage Travel Guide Entry**\\n\\n\n",
    "**Historical Document**\\n\\n\n",
    "```\n",
    "\n",
    "It should learn to use that hints, but it is likely that they are not present on the test dataset. It's just 1.4k samples that can be manually cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the samples used for evaluation do not have any sense. Maybe we have to create a high quality dataset of real use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prometeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
