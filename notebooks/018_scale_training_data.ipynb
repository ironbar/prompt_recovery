{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create similar prompts datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GPT4 API to create a diverse and high quality dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from prometeo.evaluation import get_sharpened_cosine_similarity, estimate_mean\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 16\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt4(prompt, temperature=0.7):\n",
    "    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'], organization=os.environ['OPENAI_API_ORG'])\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_progress(submits):\n",
    "    progress = 0\n",
    "    with tqdm(total=len(submits), smoothing=0) as progress_bar:\n",
    "        while 1:\n",
    "            time.sleep(1)\n",
    "            current_progress = np.sum([submit.done() for submit in submits])\n",
    "            if current_progress > progress:\n",
    "                progress_bar.update(current_progress - progress)\n",
    "                progress = current_progress\n",
    "            if progress == len(submits):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select seed prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\n",
    "    '/mnt/hdd0/Kaggle/llm_prompt_recovery/data/high_quality_dataset_imitation_of_leaked_v1.csv',\n",
    "    '/mnt/hdd0/Kaggle/llm_prompt_recovery/data/high_quality_dataset_v2.csv',\n",
    "    '/mnt/hdd0/Kaggle/llm_prompt_recovery/data/high_quality_dataset_v5_gpt4.csv',\n",
    "    '/mnt/hdd0/Kaggle/llm_prompt_recovery/data/high_quality_multi_instruction_v1.csv',\n",
    "    '/mnt/hdd0/Kaggle/llm_prompt_recovery/data/mooney_test_with_gpt4_v2.csv',\n",
    "    '/mnt/hdd0/Kaggle/llm_prompt_recovery/data/gemma_suppl_rewrite_curated_with_gpt4.csv',\n",
    "]\n",
    "df = pd.concat([pd.read_csv(filepath) for filepath in filepaths], ignore_index=True)\n",
    "df = df[['original_text', 'rewritten_text', 'rewrite_prompt']]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_prompts = df.rewrite_prompt.unique()\n",
    "print(len(seed_prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompts_template = \"\"\"Your task is to generate new, realistic and diverse prompts that could be used to rewrite some text.\n",
    "Below you can find some examples of prompts for inspiration.\n",
    "Please create 20 new prompts and answer them with a list in json format.\n",
    "\n",
    "Use this format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"prompts\": [\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "## Examples of prompts:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def generate_new_prompts(n_runs, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    with ProcessPoolExecutor(max_workers=40) as pool:\n",
    "        submits = []\n",
    "        for _ in tqdm(range(n_runs), desc='Creating submits'):\n",
    "            prompt = new_prompts_template + '\\n'.join(np.random.choice(seed_prompts, 10, replace=False))\n",
    "            submits.append(pool.submit(chat_with_gpt4, prompt))\n",
    "        monitor_progress(submits)\n",
    "        results = [submit.result() for submit in submits]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_new_prompts(n_runs=100, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompts = []\n",
    "for result in results:\n",
    "    new_prompts.extend(json.loads(result)['prompts'])\n",
    "len(new_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_prompts, columns=['prompt'])\n",
    "df.to_csv('/mnt/hdd0/Kaggle/llm_prompt_recovery/data/prompts/prompts_v3_scale.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_prompts(n_runs, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    with ProcessPoolExecutor(max_workers=40) as pool:\n",
    "        submits = []\n",
    "        for _ in tqdm(range(n_runs), desc='Creating submits'):\n",
    "            prompt = new_prompts_template + '\\n'.join(np.random.choice(seed_prompts, 10, replace=False))\n",
    "            submits.append(pool.submit(chat_with_gpt4, prompt))\n",
    "        monitor_progress(submits)\n",
    "        results = [submit.result() for submit in submits]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the following text prompt your task is to:\n",
    "\n",
    "1. Write a short text that could have sense to be modified with the given text prompt. The number of words should be less than 200.\n",
    "2. Rewrite the text using the given text prompt.\n",
    "\n",
    "The output should be in json, with the following format:\n",
    "\n",
    "{\"original_text\": \"...\", \"rewritten_text\": \"...\"}\n",
    "\n",
    "## Text prompt\n",
    "\n",
    "```PLACEHOLDER```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=40) as pool:\n",
    "    submits = []\n",
    "    for prompt in tqdm(new_prompts, desc='Creating submits'):\n",
    "        prompt = prompt_template.replace('PLACEHOLDER', prompt)\n",
    "        submits.append(pool.submit(chat_with_gpt4, prompt))\n",
    "    monitor_progress(submits)\n",
    "    results = [submit.result() for submit in submits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of this generation was around 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for prompt, result in tqdm(zip(new_prompts, results), total=len(new_prompts)):\n",
    "    try:\n",
    "        row = json.loads(result)\n",
    "        row['rewrite_prompt'] = prompt\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f'Error with prompt: {prompt}')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/mnt/hdd0/Kaggle/llm_prompt_recovery/data/high_quality_dataset_v6_scale.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prometeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
